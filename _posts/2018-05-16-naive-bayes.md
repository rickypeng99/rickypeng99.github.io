---
layout: posts
comments: true
title: 利用Naive Bayes（朴素贝叶斯）实现手写数字识别 -  实现理论篇
---
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
# 利用Naive Bayes（朴素贝叶斯）实现手写数字识别 - 实现理论篇
## 0. 写在最开头的废话
**0.1**  
之前就听过大佬讲，实力提升的关键之一是持续的输出。我在学术上是几乎从未输出过自己的见解的。虽然我的输出指的都是造轮子，但是在输出的同时其实还是可以让自己能够加深对某些方面的概念的理解。如今final已经考完，面对如此无聊的暑假，我觉得输出一点自己所知道的东西也是一件很有意义的事情。

## 1. 导言
**1.1**  
Naive Bayes是机器学习应用的一个典型例子。其核心思想即是分析训练模型，并且通过训练模型来构建一个由各种概率计算组成的新的数学模型，并且利用这个模型来分析、预测之后的数据，从而让电脑能实现人类所理解的『学习』的概念。因此，Naive Bayes又是一种分类器(classifier)，即可以通过这个算法为各种数据进行智能的分类。这个分类概念最能直观运用的便是识别手写数字了。我们可以将不同的数字想象为10个类别，即0-9，而Naive Bayes可以很好地帮助我们对不同的手写数字进行分类，也就是将长得像1的数字给识别为『1』。  
**1.2**  
Naive Bayes可以被细分为三个主要步骤：
1. **训练**  
 通过读取大量的训练数据，分析原始数据和其给定分类，然后构建概率模型，用于分类和预测之后的数据。本片文章使用的训练模型为5000组手写数字图片及其对应的数字。
2. **分类**  
 通过读取概率模型并将其运用到之后的数据上，利用原始的经验概率数据计算出每一个该图像成为每一种类的后验概率，然后进行分类（如果这个图片成为1的后验概率最高，那么这个图片就会被分类为『1』。本篇文章将对1000组手写数字进行分类，Naive bayes算法可以在经过学习5000组认字学习后正确识别771个手写数字。
3. **其他**  
 我们可以利用后验概率进行其他的对数据的分析。比如：哪些手写的数字『1』长得最像『1』。  

## 2. 训练
**2.1 理解手写数字**  
我们可以将一个手写数字想象为一个28*28大小的像素图。这个图的颜色是二元的，非黑即白。灰色（可被视为黑色）的像素块我们可以用符号『+』表示，黑色的像素块我们可以用符号『#』 表示，白色的像素块我们用空格来表示。因此，一个手写数字5可以被如下所表示：  







                +++++##+    
        +++++######+###+    
       +##########+++++     
        #######+##          
        +++###  ++          
           +#+              
           +#+              
            +#+             
            +##++           
             +###++         
              ++##++        
                +##+        
                 ###+       
              +++###        
            ++#####+        
          ++######+         
        ++######+           
       +######+             
    ++######+               
    +####++                 






**2.2  贝叶斯定理(Bayes theorem)**  
Naive Bayes作为一个利用概率模型进行分类的算法，其核心是基于Bayes theorem（贝叶斯定理）。贝叶斯定理可以用于计算一个事件A在事件B发生的时候发生的概率。  
> $$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$    
$$P(A|B)$$是在B事件的先决条件下发生A事件的概率  
$$P(B|A)$$是在A事件的先决条件下发生B事件的概率  
* $$P(A)$$是指A事件发生的概率（无关于B）  
* $$P(B)$$是指B事件发生的概率（无关于A），且$$P(B)$$不等于0。   


**2.3 将Bayes定理运用到手写数字识别中 - 经验概率**  
Bayes定理是求得$$P(A|B)$$，那么相应的，针对于识别手写数字，我们可以为每个类别构建一个如下的经验概率（empirical probability)。即当目前的类别的为$$c\in\{0, 1, ..., 9\}$$时，位于像素点$$i,j (Fi,j)$$的值为$$f\in\{0,1\}$$的概率，其中0为白色，1为黑色。黑白二色，各有一个概率。  

使用数学公式概括即为：      
$$P(Fi,j = f|class = c)=\frac{当class = c时，Fij = f的次数}{class = c的总次数}$$

**2.4 使用拉普拉斯平滑(Laplace smoothing)优化概率数据**  
概率数据可能会出现0。比如在像素点[1,1]的时候(图片的左上角)，是几乎不可能为黑色或者灰色的。为了完全避免这种情况的发生(概率为0会对后续的后验概率(posterior possibility)计算造成影响)，我们需要使用拉普拉斯平滑(Laplace smoothing)来优化数据，让为0的的概率变为极小的小数，从而并不会影响概率的计算。拉普拉斯平滑的实现在这里很简单。只需在$$P(Fi,j = f|class = c)$$的分子上加上一个常量K，并在分母加上K*V。其中V等于每个像素点可能拥有的内容的个数（照片只有黑和白，所以这里的V为2）。  
不同的K值会带来不同的效果，目前并没有除了一个一个试以外的方法得知哪个K值可以让AI最终成功识别最多的手写数字（在本篇文章所使用的数据中，使用K = 1可以最大化正确率）。当然，K值越大，平滑的程度也就越大。

使用数学公式概括即为：      
$$P(Fi,j = f|class = c)=\frac{K + 当class = c时，Fij = f的次数}{2K + class = c的总次数}$$  

**2.5 先验概率(prior probability)**
一组训练数据势必会产生不同数量的0-9，因此，为了后续后验概率的计算，我们还需计算出每个数字类别占总量的多少。因为经验概率的数值都是相对于自身的。

使用数学公式概括即为：      
$$P(class = c)=\frac{训练数据里class = c的次数}{训练数据的总个数}$$

**2.6 概率模型**
为了方便后续计算的使用，现阶段所有所得到概率数据可以用一个四维数组存放经验概率，然后由一个一位数组存放先验概率。  
存放经验概率的四个维度为：[像素点i][像素点j][类别(0-9)][颜色(0-1)]。  
存放先验概率即为十个不同数字类别。  

## 3. 分类
**3.1 最大后验概率分类(Maximum a posteriori (MAP) classification)**  
在得到所有的概率数据模型之后，我们可以计算每张图片的后验概率（posterior probabilities，也就是这个图片成为某个类别的概率），然后根据哪个类别对于这个图片拥有最大的后验概率，就将手写数字图片分类到哪个类别里。这便是最大后验概率分类。  
每张图的后验概率的计算很简单。我们只需要将一张图片所包含的所有经验概率相乘，以及最后还要再乘上先验概率。  

使用数学公式概括即为：   
$$P(class) ∗ P(f1,1|class) ∗ P(f1,2|class) ∗ ... ∗ P(f28,28|class)$$  

**3.2 处理数值下溢(arithmitic underflow)**  
实数是无限且不可数的，而计算机能够用来表示实数的bit是有限且可数的。因此，对于过小的数值，计算机往往会取整为0，造成数值下溢。为了避免这个情况，我们可以使用经验和先验概率的log来计算后验概率。

使用数学公式概括即为：   
$$log(P(class)) + log(P(f1,1|class)) + log(P(f1,2|class)) + ... + log(P(f28,28|class))$$

**3.3 实现分类**  
实现分类的最后一步便是找出每张图最大的后验概率所对应的类别了。举个例子:  

| class | posterior probability |
|-------|-----------------------|
| 0     | 0.3141                |
| 1     | 0.432                 |
| 2     | 0                     |
| 3     | 0                     |
| 4     | 0.4                   |
| 5     | 0.004                 |
| 6     | 0.1                   |
| 7     | 0.2                   |
| 8     | 0.7                   |
| 9     | 0.5                   |  

如上图所示，因为『8』的后验概率最高，因此这个手写数字图会被分类到『8』。
